# Brand Video Processing Pipeline

This project implements a pipeline to process videos, extract unique slides, and compare them using embeddings generated by the CLIP model. The system can identify slides in a video, extract unique slides, and match them against a reference slide deck.

## Overview

The pipeline consists of three main steps:

1. **Extract unique slides from a video** - Detect and save unique frames by filtering out transitions, blurred frames, and duplicates
2. **Generate image embeddings** - Use the CLIP model to create vector representations of slides and frames
3. **Compare frames to slides** - Match extracted frames against reference slides using cosine similarity

## Requirements

- Python 3.8+
- OpenCV (`cv2`)
- NumPy
- PyTorch
- scikit-learn
- CLIP (Contrastive Language-Image Pre-training)

## Installation

```bash
pip install opencv-python numpy torch torchvision scikit-learn
pip install git+https://github.com/openai/CLIP.git
```

## Project Structure

```
├── clipmodel.py          # CLIP model wrapper for generating embeddings
├── embed_and_match.py    # Compare frames to slides using CLIP embeddings
├── extract_bordered.py   # Extract bordered content from slides
├── keyframe.py           # Extract keyframes from video
├── transition.py         # Detect and handle transitions in video
├── unique.py             # Identify unique slides using histogram comparison
├── frames/               # Directory containing extracted frames
├── slides/               # Directory containing reference slides
├── unique_slides/        # Directory for storing unique slides
```

## Usage

### Step 1: Extract Frames from Video

The `transition.py` script processes a video file to extract unique slides:

```bash
python transition.py
```

This will:
- Process the video file (default: Testvid.mp4)
- Extract frames at regular intervals
- Skip transitions and blurred frames
- Detect and save only unique slides to the `unique_slides` folder

Configuration options:
- `frame_skip`: Number of frames to skip between processing (default: 5)
- `pixel_threshold`: Threshold for transition detection
- `blur_threshold`: Threshold for blur detection
- `similarity_threshold`: Threshold for slide similarity (0.0-1.0)

### Step 2: Extract Unique Slides

If you already have a folder with frames, you can extract unique ones using:

```bash
python unique.py
```

This will:
- Process all images in the `frames` folder
- Compare images using histogram comparison
- Save only unique slides to the `unique_slides` folder

### Step 3: Generate Embeddings and Match Frames to Slides

```bash
python embed_and_match.py
```

This will:
- Generate CLIP embeddings for all slides in the `slides` folder
- Generate CLIP embeddings for all frames in the `unique_slides` folder
- Compare embeddings using cosine similarity
- Identify matches between frames and slides based on a similarity threshold

## Key Functions

### transition.py

- `is_transition_frame`: Detects transition frames using pixel difference between consecutive frames
- `is_blurred_frame`: Detects blurred frames using the variance of Laplacian
- `is_similar_slide`: Compares frames using Structural Similarity Index (SSIM)

### unique.py

- `is_similar_slide`: Compares two slides using histogram comparison
- `save_unique_slides`: Processes a folder of slides to save only unique ones

### clipmodel.py

- `get_image_embedding`: Generates CLIP embeddings for an image

### embed_and_match.py

- `compare_frames_to_slides`: Compares frames to slides using CLIP embeddings and cosine similarity

## Parameters and Their Impact

- **pixel_threshold** (Transition Detection):
  - Higher values: More frames pass as non-transitions
  - Lower values: Stricter transition detection

- **blur_threshold** (Blur Detection):
  - Higher values: More frames pass as non-blurred
  - Lower values: Stricter blur detection

- **similarity_threshold** (SSIM or Cosine Similarity):
  - Higher values: Stricter comparison, fewer matches
  - Lower values: More lenient comparison, more matches

- **frame_skip**:
  - Higher values: Process fewer frames, faster execution
  - Lower values: Process more frames, capture more subtle changes

## Customization

You can adjust parameters in each script to optimize for your specific videos and slides:

1. Edit `transition.py` to adjust frame extraction parameters
2. Edit `unique.py` to adjust the similarity threshold for histogram comparison
3. Edit `embed_and_match.py` to adjust the similarity threshold for CLIP embedding comparison

## Improvement Opportunities

- **Optimize thresholds** for your specific videos and slides
- **Enhance similarity detection** using multiple comparison methods
- **Add preprocessing steps** like resize, contrast enhancement, etc.
- **Parallelize embedding generation** for large datasets
- **Add visualization tools** to display matches and non-matches

## Troubleshooting

- If transitions are not properly detected, adjust `pixel_threshold`
- If blurred frames are not properly filtered, adjust `blur_threshold`
- If too many/few unique slides are detected, adjust `similarity_threshold`
- If embedding matching is incorrect, adjust the CLIP similarity threshold
